{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metrics(y_true,y_pred):\n",
    "    print(\"accurracy: {}\".format(accuracy_score(y_true,y_pred)))\n",
    "    #print(\"f1: {}\".format(f1_score(y_true,y_pred,average=\"macro\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current best for universities:\n",
    "RandomForestClassifier 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0bba44e847cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bd_hielo.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"len\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cie\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"his\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"nem\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"universidad\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#randomized stratified test/train split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"bd_hielo.csv\")\n",
    "X = np.array(data[[\"mat\",\"len\",\"cie\",\"his\",\"nem\"]])\n",
    "y= np.array(data[\"universidad\"])\n",
    "X_scaled = scale(X)\n",
    "#randomized stratified test/train split\n",
    "sss = StratifiedShuffleSplit(n_splits=5, train_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy: 0.24192415730337077\n",
      "accurracy: 0.2345505617977528\n",
      "accurracy: 0.23525280898876405\n",
      "accurracy: 0.22787921348314608\n",
      "accurracy: 0.2345505617977528\n"
     ]
    }
   ],
   "source": [
    "#25%\n",
    "for train_index,test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = RandomForestClassifier(50)\n",
    "    model.fit(X_train,y_train)\n",
    "    result = model.predict(X_test)\n",
    "    print_metrics(y_test,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#22%\n",
    "for train_index,test_index in sss.split(X_scaled, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = SVC(decision_function_shape='ovr')\n",
    "    model.fit(X_train,y_train)\n",
    "    result = model.predict(X_test)\n",
    "    print_metrics(y_test,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy: 0.20962078651685392\n",
      "accurracy: 0.21523876404494383\n",
      "accurracy: 0.22120786516853932\n",
      "accurracy: 0.20470505617977527\n",
      "accurracy: 0.21067415730337077\n"
     ]
    }
   ],
   "source": [
    "#22% \n",
    "for train_index,test_index in sss.split(X_scaled, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = KNeighborsClassifier(n_neighbors=20,n_jobs=-1)\n",
    "    model.fit(X_train,y_train)\n",
    "    result = model.predict(X_test)\n",
    "    print_metrics(y_test,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy: 0.1776685393258427\n",
      "accurracy: 0.17485955056179775\n",
      "accurracy: 0.16643258426966293\n",
      "accurracy: 0.19627808988764045\n",
      "accurracy: 0.1934691011235955\n"
     ]
    }
   ],
   "source": [
    "#18%\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "le = LabelBinarizer()\n",
    "le.fit(y)\n",
    "y_transformed = le.transform(y)\n",
    "for train_index,test_index in sss.split(X_scaled, y_transformed):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100),activation=\"logistic\")\n",
    "    model.fit(X_train,y_train)\n",
    "    result = model.predict(X_test)\n",
    "    print_metrics(y_test,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy: 0.20189606741573032\n",
      "accurracy: 0.20751404494382023\n",
      "accurracy: 0.18714887640449437\n",
      "accurracy: 0.1797752808988764\n",
      "accurracy: 0.1857443820224719\n"
     ]
    }
   ],
   "source": [
    "#19%\n",
    "for train_index,test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train,y_train)\n",
    "    result = model.predict(X_test)\n",
    "    print_metrics(y_test,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy: 0.16853932584269662\n",
      "accurracy: 0.19662921348314608\n",
      "accurracy: 0.19241573033707865\n",
      "accurracy: 0.20259831460674158\n",
      "accurracy: 0.16853932584269662\n"
     ]
    }
   ],
   "source": [
    "#20%\n",
    "for train_index,test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = AdaBoostClassifier(n_estimators=50,algorithm=\"SAMME\")\n",
    "    model.fit(X_train,y_train)\n",
    "    result = model.predict(X_test)\n",
    "    print_metrics(y_test,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
